{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9bfc805-34b5-42fd-9d3c-e4536fa80510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import tqdm\n",
    "import glob\n",
    "import mmcv\n",
    "import numpy as np\n",
    "from accelerate import Accelerator\n",
    "from mmdet.structures import DetDataSample\n",
    "from mmengine.structures import InstanceData\n",
    "from mmdet.models.test_time_augs.merge_augs import merge_aug_results\n",
    "\n",
    "from utils import modules, custom_dataset\n",
    "\n",
    "import json\n",
    "from ensemble_boxes import weighted_boxes_fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3983c17b-758a-46a1-9ae0-faa55e41ce99",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator(mixed_precision=None)\n",
    "device = accelerator.device\n",
    "\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dc344f3-9e94-4947-9315-1139a6613abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "NUM_WORKDERS = 1\n",
    "IMG_PREFIX = \"data/test2/\"\n",
    "PSEUDO_THREHSOLD = .6\n",
    "\n",
    "MODEL_CFG_CONFIG = \"config.py\"\n",
    "\n",
    "MODEL_NAME = \"RTMDet\"\n",
    "model_path = \"work_dir/RTMDet_model.pt\"\n",
    "tta_type = [None, \"hor\", 1.3, .8, \"ver\", 90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef3e0946-d206-46f3-b5fb-1836a72133de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDatset(torch.utils.data.Dataset):\n",
    "    after_transform = A.Compose(\n",
    "        [\n",
    "            A.Normalize(),\n",
    "            ToTensorV2()\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    hor = A.Compose([A.HorizontalFlip(p=1.)])\n",
    "    ver = A.Compose([A.VerticalFlip(p=1.)])\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        img_prefix=\"data/test1/\",\n",
    "        fill_pad_factor=32,\n",
    "        fill_pad_value=255\n",
    "    ):\n",
    "        \"\"\" 自定义加载数据集\n",
    "        \n",
    "        Args:\n",
    "            img_prefix (str): 图片的根目录\n",
    "            fill_pad_factor (int): 将宽高填充至倍数\n",
    "            fill_pad_value (int): 填充值\n",
    "        \"\"\"\n",
    "        self.images = sorted(glob.glob(f\"{img_prefix}/*.jpg\"))\n",
    "        \n",
    "        self.fill_pad_factor = fill_pad_factor\n",
    "        self.fill_pad_value = fill_pad_value\n",
    "        self.len = len(self.images)\n",
    "        \n",
    "        self.type = None\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        x = mmcv.imread(img, channel_order=\"rgb\")\n",
    "        inputs, data_sample = self.pipeline(x)\n",
    "        \n",
    "        return inputs, data_sample\n",
    "    \n",
    "    def pipeline(self, img, image_id=None):\n",
    "        org_h, org_w, _ = img.shape\n",
    "        h, w, c = img.shape\n",
    "        scale_factor = (1., 1.)\n",
    "        flip = False\n",
    "        flip_direction = \"y\"\n",
    "        if self.type == \"hor\":\n",
    "            item = self.hor(image=img)\n",
    "            img = item[\"image\"]\n",
    "        elif self.type == \"ver\":\n",
    "            item = self.ver(image=img)\n",
    "            img = item[\"image\"]\n",
    "        elif self.type is None:\n",
    "            ...\n",
    "        elif isinstance(self.type, float):\n",
    "            new_h, new_w = int(h * self.type), int(w * self.type)\n",
    "            item = A.Resize(new_h, new_w)(image=img)\n",
    "            img = item[\"image\"]\n",
    "            new_h, new_w, c = img.shape\n",
    "            scale_factor = (new_w / w, new_h / h)\n",
    "            h, w = new_h, new_w\n",
    "        elif self.type == 90:\n",
    "            img = np.rot90(img, 1, (0, 1))\n",
    "            h, w, c = img.shape\n",
    "        else:\n",
    "            raise ValueError(f\"不能解释的类型：{self.type}\")\n",
    "\n",
    "        pad_h = h\n",
    "        pad_w = w\n",
    "        if (\n",
    "            h % self.fill_pad_factor != 0 or\n",
    "            w % self.fill_pad_factor != 0\n",
    "        ):\n",
    "            if h % self.fill_pad_factor != 0:\n",
    "                pad_h = (h // self.fill_pad_factor + 1) * self.fill_pad_factor\n",
    "                \n",
    "            if w % self.fill_pad_factor != 0:\n",
    "                pad_w = (w // self.fill_pad_factor + 1) * self.fill_pad_factor\n",
    "             \n",
    "            pad_img = np.full((pad_h, pad_w, c), self.fill_pad_value, dtype=img.dtype)\n",
    "            pad_img[:h, :w] = img\n",
    "            img = pad_img\n",
    "        \n",
    "        item = self.after_transform(image=img)\n",
    "        img = item[\"image\"]\n",
    "        \n",
    "        data_sample = DetDataSample()\n",
    "        img_meta = dict(\n",
    "            org_shape=(org_h, org_w),\n",
    "            img_shape=(h, w),\n",
    "            pad_shape=(pad_h, pad_w),\n",
    "            scale_factor=scale_factor,\n",
    "            image_id=image_id,\n",
    "            keep_ratio=True,\n",
    "            flip=flip,\n",
    "            flip_direction=flip_direction,\n",
    "        )\n",
    "\n",
    "        data_sample.set_metainfo(img_meta)\n",
    "\n",
    "        return img, data_sample\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beaf7241-6fdc-4292-b59e-601a96d03bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TTA:\n",
    "    def __init__(self, model, dataloader):\n",
    "        \"\"\" TTA 适用 batch size 为1的情况 \"\"\"\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.dataloader = dataloader\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def __call__(self, types=None):\n",
    "        \"\"\" \n",
    "        Args：\n",
    "            types: 图片变换类型\n",
    "                float: 图片缩放比例\n",
    "                None: 原图训练\n",
    "                \"hor\": 水平翻转\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        self.dataloader.dataset.type = types\n",
    "        res = []\n",
    "        dataloader = tqdm.tqdm(self.dataloader)\n",
    "        for batch in dataloader:\n",
    "            out = self.model(batch, mode=\"predict\")[0]\n",
    "            pred = out.pred_instances\n",
    "            h, w = batch[\"data_samples\"][0].org_shape\n",
    "            img_meta = dict(\n",
    "                # 原图高宽\n",
    "                img_shape=(h, w),\n",
    "            )\n",
    "            if isinstance(types, float) or types is None:\n",
    "                # 缩放，在 mmdet 中会自动缩放\n",
    "                ...\n",
    "            elif types == \"hor\":\n",
    "                # 水平翻转\n",
    "                bbox = pred.bboxes.clone()\n",
    "                pred.bboxes[:, [0, 2]] = w - bbox[:, [2, 0]]\n",
    "            elif types == \"ver\":\n",
    "                # 垂直翻转\n",
    "                bbox = pred.bboxes.clone()\n",
    "                pred.bboxes[:, [1, 3]] = h - bbox[:, [3, 1]]\n",
    "            elif types == 90:\n",
    "                ...\n",
    "                # 旋转 90°\n",
    "                bbox = pred.bboxes.clone()\n",
    "                pred.bboxes[:, 0] = w - bbox[:, 3]\n",
    "                pred.bboxes[:, 1] = bbox[:, 0]\n",
    "                pred.bboxes[:, 2] = w - bbox[:, 1]\n",
    "                pred.bboxes[:, 3] = bbox[:, 2]\n",
    "            else:\n",
    "                raise ValueError(f\"不能解释的类型：{types}\")\n",
    "            pred.set_metainfo(img_meta)\n",
    "                \n",
    "            results.append(pred)\n",
    "        \n",
    "        self.dataloader.dataset.type = None\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee4b8b5b-8a73-4308-811c-f0c902e471b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Keys Matching\n"
     ]
    }
   ],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    CustomDatset(\n",
    "        IMG_PREFIX,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKDERS,\n",
    "    shuffle=False,\n",
    "    collate_fn=custom_dataset.collate_fn\n",
    ")\n",
    "\n",
    "model = modules.Model(MODEL_CFG_CONFIG)\n",
    "model.load_state_dict(torch.load(model_path, \"cpu\")[\"model\"])\n",
    "\n",
    "model, test_dataloader = accelerator.prepare(\n",
    "    model, \n",
    "    test_dataloader\n",
    ")\n",
    "\n",
    "tta = TTA(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05f6fdb9-bb6a-4b92-ac74-174a22502219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1887 [00:00<?, ?it/s]/home/zhy/miniconda3/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1678411187366/work/aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "100%|██████████| 1887/1887 [01:26<00:00, 21.86it/s]\n",
      "100%|██████████| 1887/1887 [01:11<00:00, 26.36it/s]\n",
      "100%|██████████| 1887/1887 [01:46<00:00, 17.64it/s]\n",
      "100%|██████████| 1887/1887 [00:57<00:00, 32.87it/s]\n",
      "100%|██████████| 1887/1887 [01:12<00:00, 26.11it/s]\n",
      "100%|██████████| 1887/1887 [01:21<00:00, 23.26it/s]\n"
     ]
    }
   ],
   "source": [
    "outputs = [tta(tt) for tt in tta_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7304633f-6680-46af-a0d7-d773176c7b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = []\n",
    "# for out in outputs:\n",
    "#     res = []\n",
    "#     for label_id in [1, 4, 3, 8, 9, 6, 5, 2, 7]:\n",
    "#         r = []\n",
    "#         pred_instances = out\n",
    "#         for i in range(len(pred_instances.labels)):\n",
    "#             if (\n",
    "#                 pred_instances.labels[i].item() == label_id and\n",
    "#                 pred_instances.scores[i].item() > 0.03\n",
    "#             ):\n",
    "#                 r.append([\n",
    "#                     b.item()\n",
    "#                     for b in pred_instances.bboxes[i].detach().cpu()\n",
    "#                 ] + [pred_instances.scores[i].detach().cpu().item()]\n",
    "#                 )\n",
    "#         res.append(r)\n",
    "#     results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c007e4cb-4a67-4233-b47b-edb28899c2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_coco = {\n",
    "    \"images\": [],\n",
    "    \"annotations\": [],\n",
    "    \"categories\": [\n",
    "        {\n",
    "            \"id\": 0,\n",
    "            \"name\": \"background\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": 1,\n",
    "            \"name\": \"knife\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": 2,\n",
    "            \"name\": \"scissor\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": 3,\n",
    "            \"name\": \"glassbottle\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": 4,\n",
    "            \"name\": \"tongs\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": 5,\n",
    "            \"name\": \"metalcup\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": 6,\n",
    "            \"name\": \"umbrella\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": 7,\n",
    "            \"name\": \"lighter\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": 8,\n",
    "            \"name\": \"pressure\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": 9,\n",
    "            \"name\": \"laptop\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "img_id = 0\n",
    "ann_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a415bebe-d9c7-4749-82fc-df7434a3d275",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhy/miniconda3/lib/python3.10/site-packages/ensemble_boxes/ensemble_boxes_wbf.py:63: UserWarning: Y2 > 1 in box. Set it to 1. Check that you normalize boxes in [0, 1] range.\n",
      "  warnings.warn('Y2 > 1 in box. Set it to 1. Check that you normalize boxes in [0, 1] range.')\n",
      "/home/zhy/miniconda3/lib/python3.10/site-packages/ensemble_boxes/ensemble_boxes_wbf.py:51: UserWarning: X2 > 1 in box. Set it to 1. Check that you normalize boxes in [0, 1] range.\n",
      "  warnings.warn('X2 > 1 in box. Set it to 1. Check that you normalize boxes in [0, 1] range.')\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for img_idx, i in enumerate(range(len(outputs[0]))):\n",
    "    h, w = outputs[0][i].img_shape\n",
    "    boxes, scores, labels = weighted_boxes_fusion(\n",
    "        boxes_list=[\n",
    "            (out[i].bboxes.cpu() / torch.tensor([w, h, w, h]).reshape(1, -1)).tolist()\n",
    "            for out in outputs\n",
    "        ],\n",
    "        scores_list=[\n",
    "            out[i].scores.tolist()\n",
    "            for out in outputs\n",
    "        ],\n",
    "        labels_list=[\n",
    "            out[i].labels.tolist()\n",
    "            for out in outputs\n",
    "        ],\n",
    "        conf_type=\"max\",\n",
    "        iou_thr=.55,\n",
    "        skip_box_thr=0.02,\n",
    "    )\n",
    "    boxes = boxes * np.array([w, h, w, h]).reshape(1, -1).tolist()\n",
    "    scores = scores.tolist()\n",
    "    labels = labels.tolist()\n",
    "    \n",
    "    cur_ann = 0\n",
    "    res = []\n",
    "    for label_id in [1, 4, 3, 8, 9, 6, 5, 2, 7]:\n",
    "        r = []\n",
    "        for i in range(len(boxes)):\n",
    "            # # # # # #\n",
    "            # Predict #\n",
    "            # # # # # #\n",
    "            if labels[i] == label_id:\n",
    "                box = boxes[i]\n",
    "                r.append([*boxes[i]] + [scores[i]])\n",
    "                \n",
    "                # # # # # #\n",
    "                # Pseudo #\n",
    "                # # # # #\n",
    "                if scores[i] > PSEUDO_THREHSOLD:\n",
    "                    box = [\n",
    "                        int(boxes[i][0]),\n",
    "                        int(boxes[i][1]),\n",
    "                        int(boxes[i][2] - boxes[i][0]),\n",
    "                        int(boxes[i][3] - boxes[i][1]),\n",
    "                    ]\n",
    "\n",
    "                    cur_ann += 1\n",
    "                    pseudo_coco[\"annotations\"].append({\n",
    "                        \"image_id\": img_id,\n",
    "                        \"id\": ann_id,\n",
    "                        \"category_id\": int(labels[i]),\n",
    "                        \"bbox\": box,\n",
    "                        \"area\": box[2] * box[3],\n",
    "                        \"segmentation\": [],\n",
    "                        \"iscrowd\": 0 if \"polygon\" else 1,\n",
    "                        \"score\": scores[i]\n",
    "                    })\n",
    "                    ann_id += 1\n",
    "        res.append(r)\n",
    "    results.append(res)\n",
    "    \n",
    "    if cur_ann > 0:\n",
    "        pseudo_coco[\"images\"].append({\n",
    "            \"id\": img_id,\n",
    "            \"file_name\": str(img_idx).rjust(5, \"0\") + \".jpg\",\n",
    "            \"height\": h,\n",
    "            \"width\": w\n",
    "        })\n",
    "        \n",
    "        img_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3610a25c-d341-4c33-a70d-80eb883d8514",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"results.json\", \"w\") as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "142a342f-f816-4710-bde4-a9b4aedec907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"data/pseudo_coco_from814_thre0.6.json\", \"w\") as f:\n",
    "#     json.dump(pseudo_coco, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6cb922-202d-43ef-af40-7f69864a5450",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
