{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "987b4364-15e2-4aec-bca3-60e7238a834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import tqdm\n",
    "import glob\n",
    "import mmcv\n",
    "import numpy as np\n",
    "from accelerate import Accelerator\n",
    "from mmdet.structures import DetDataSample\n",
    "\n",
    "from utils import modules, custom_dataset\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7910a9ae-e8fa-426a-b77d-9905ba190fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator()\n",
    "device = accelerator.device\n",
    "\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e558e6-b76e-4225-9376-5539b653be73",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eed3a6f5-33e5-49d0-b213-5e40d7a69c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "BATCH_SIZE = 1\n",
    "NUM_WORKDERS = 1\n",
    "VALID_RESOLUTION = 1e8\n",
    "IMG_PREFIX = \"data/test1/\"\n",
    "\n",
    "MODEL_CFG_CONFIG = \"config.py\"\n",
    "\n",
    "test_transform = A.Compose(\n",
    "    [\n",
    "        A.SmallestMaxSize(max_size=VALID_RESOLUTION, p=1.),\n",
    "    ]\n",
    ")\n",
    "\n",
    "MODEL_NAME = \"RTMDet\"\n",
    "model_path = \"work_dir/RTMDet_model.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0f384a-41b8-42e9-8e0b-473b10a36617",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f9943c6-78a5-4922-8de1-5d2880f0d374",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDatset(torch.utils.data.Dataset):\n",
    "    after_transform = A.Compose(\n",
    "        [\n",
    "            A.Normalize(),\n",
    "            ToTensorV2()\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        img_prefix=\"data/train/\",\n",
    "        transform=None,\n",
    "        fill_pad_factor=32,\n",
    "        fill_pad_value=114\n",
    "    ):\n",
    "        \"\"\" 自定义加载数据集\n",
    "        \n",
    "        Args:\n",
    "            img_prefix (str): 图片的根目录\n",
    "            transform (albumentations): 图像增强\n",
    "            fill_pad_factor (int): 将宽高填充至倍数\n",
    "            fill_pad_value (int): 填充值\n",
    "        \"\"\"\n",
    "        self.images = sorted(glob.glob(f\"{img_prefix}/*.jpg\"))\n",
    "        \n",
    "        self.fill_pad_factor = fill_pad_factor\n",
    "        self.fill_pad_value = fill_pad_value\n",
    "        self.transform = transform\n",
    "        self.len = len(self.images)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        x = mmcv.imread(img, channel_order=\"rgb\")\n",
    "        \n",
    "        inputs, data_sample = self.pipeline(x)\n",
    "        return inputs, data_sample\n",
    "    \n",
    "    def pipeline(self, img, image_id=None):\n",
    "        h, w, c = img.shape\n",
    "        scale_factor = (1., 1.)\n",
    "        if (\n",
    "            h > VALID_RESOLUTION and\n",
    "            w > VALID_RESOLUTION and\n",
    "            self.transform is not None\n",
    "        ):\n",
    "            item = self.transform(image=img)\n",
    "            img = item[\"image\"]\n",
    "            new_h, new_w, c = img.shape\n",
    "            scale_factor = (new_h / h, new_w / w)\n",
    "            h, w = new_h, new_w\n",
    "            \n",
    "        pad_h = h\n",
    "        pad_w = w\n",
    "        if (\n",
    "            h % self.fill_pad_factor != 0 or\n",
    "            w % self.fill_pad_factor != 0\n",
    "        ):\n",
    "            if h % self.fill_pad_factor != 0:\n",
    "                pad_h = (h // self.fill_pad_factor + 1) * self.fill_pad_factor\n",
    "                \n",
    "            if w % self.fill_pad_factor != 0:\n",
    "                pad_w = (w // self.fill_pad_factor + 1) * self.fill_pad_factor\n",
    "            \n",
    "            pad_img = np.full((pad_h, pad_w, c), self.fill_pad_value, dtype=img.dtype)\n",
    "            pad_img[:h, :w] = img\n",
    "            img = pad_img\n",
    "            \n",
    "        item = self.after_transform(image=img)\n",
    "        img = item[\"image\"]\n",
    "        \n",
    "        data_sample = DetDataSample()\n",
    "        img_meta = dict(\n",
    "            img_shape=(h, w),\n",
    "            pad_shape=(pad_h, pad_w),\n",
    "            scale_factor=scale_factor,\n",
    "            image_id=image_id,\n",
    "            keep_ratio=True,\n",
    "            filp=False,\n",
    "        )\n",
    "\n",
    "        data_sample.set_metainfo(img_meta)\n",
    "\n",
    "        return img, data_sample\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d059924-a15e-4fdb-bfbf-89db97c69c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    CustomDatset(\n",
    "        IMG_PREFIX,\n",
    "        test_transform,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKDERS,\n",
    "    shuffle=False,\n",
    "    collate_fn=custom_dataset.collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9608ccdf-3a2b-4b86-a615-eddfcc2fec7d",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0edff555-ae7c-4e9a-8fff-a9a706bff72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Keys Matching\n"
     ]
    }
   ],
   "source": [
    "model = modules.Model(MODEL_CFG_CONFIG)\n",
    "model.load_state_dict(torch.load(model_path, \"cpu\")[\"model\"])\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9dacec-2b0f-4c0f-b5ee-1381978e4dc5",
   "metadata": {},
   "source": [
    "# Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "170da306-7a00-47ed-8453-58c391576e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, test_dataloader = accelerator.prepare(\n",
    "    model, \n",
    "    test_dataloader\n",
    ")\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_one_epoch(model, dataloader):\n",
    "    dataloader = tqdm.tqdm(dataloader, disable=not accelerator.is_main_process)\n",
    "    \n",
    "    model.eval()\n",
    "    predict = []\n",
    "    for batch in dataloader:\n",
    "        out = model(batch, mode=\"predict\")\n",
    "        for data_sample in out:\n",
    "            image_id = data_sample.image_id\n",
    "            pred_instances = data_sample.pred_instances\n",
    "            for i in range(len(pred_instances.labels)):\n",
    "                bbox = pred_instances.bboxes[i].detach().cpu()\n",
    "                bbox[2:] = bbox[2:] - bbox[:2]\n",
    "                predict.append(\n",
    "                    np.array([\n",
    "                        image_id,\n",
    "                        *bbox,\n",
    "                        pred_instances.scores[i].detach().cpu(),\n",
    "                        pred_instances.labels[i].detach().cpu()\n",
    "                    ])\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2792a85-0f33-4995-8ac4-665854a14157",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1132 [00:00<?, ?it/s]/home/zhy/miniconda3/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1678411187366/work/aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "  5%|▌         | 59/1132 [00:07<02:09,  8.27it/s]"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "dataloader = tqdm.tqdm(test_dataloader, disable=not accelerator.is_main_process)\n",
    "\n",
    "\"\"\"\n",
    "'knife': 1\n",
    "'tongs': 2\n",
    "'glassbottle': 3\n",
    "'pressure': 4\n",
    "'laptop': 5\n",
    "'umbrella': 6\n",
    "'metalcup': 7\n",
    "'scissor': 8\n",
    "lighter': 9\n",
    "\"\"\"\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        out = model(batch, mode=\"predict\")\n",
    "        res = []\n",
    "        for data_sample in out:\n",
    "            for label_id in [1, 4, 3, 8, 9, 6, 5, 2, 7]:\n",
    "                r = []\n",
    "                pred_instances = data_sample.pred_instances\n",
    "                for i in range(len(pred_instances.labels)):\n",
    "                    if pred_instances.labels[i].item() == label_id:\n",
    "                        r.append([\n",
    "                            b.item()\n",
    "                            for b in pred_instances.bboxes[i].detach().cpu()\n",
    "                        ] + [min(1, max(0.001, pred_instances.scores[i].detach().cpu().item()))]\n",
    "                        )\n",
    "                res.append(r)\n",
    "        results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f150cc02-9316-4f5f-98ef-d9bde20fd0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results.json\", \"w\") as f:\n",
    "    json.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
